---
title: "Forecasting Short-Term Anomalies in AtHub’s (603881.SH) Stock Behavior"
subtitle: "Data-Driven Detection of Local Peaks and Dips"
author: 
  - name: "Team A - Team member Annabelle Zhu"
    affiliations:
      - name: "College of Information Science, University of Arizona"
description: "Project description"
format:
  html:
    code-tools: true
    code-overflow: wrap
    code-line-numbers: true
    embed-resources: true
editor: visual
code-annotations: hover
execute:
  warning: false
jupyter: python3
---
# High-Level Goal

To develop a machine learning classifier that predicts next-day abnormal volatility events in AtHub (603881.SH) stock using technical analysis (TA) indicators, with anomalies defined as price movements exceeding ±5% or volume surges >2× the 30-day average.


```{python}
#| label: load-pkgs
#| message: false
import numpy as np
import pandas as pd
```

## Dataset

```{python}
#| label: load-dataset
#| message: false
df = pd.read_csv("data/stock_cleaned.csv")
df.head()
```


```{python}
f"Dataset contains {df.shape[0]} rows and {df.shape[1]} columns."
```

```{python}
df.info()

```


### **Motivation & Goals**

**Why AtHub (603881.SH)?**
AtHub is a leading Chinese data center infrastructure provider whose stock exhibits unusually high short-term volatility, making it a strong candidate for anomaly-based forecasting. Over the past six months, its daily return volatility (σ ≈ 35%) has far exceeded the industry average (≈ 22%). Moreover, its price reacts sharply to regulatory announcements and policy shifts, reflecting its sensitivity to macro-level and sector-specific events.

This project aims to detect and forecast short-term abnormal volatility events in AtHub’s stock using supervised machine learning. Instead of heuristic rules, we define volatility anomalies using **quantifiable thresholds**: price changes beyond ±5% or trading volumes exceeding 2× the 30-day average. Our key goals are:

* **Build an interpretable prediction model** using over 30 engineered technical indicators (e.g., MACD, RSI, OBV, ATR).
* **Evaluate event-driven prediction performance** using time-series-aware cross-validation and dynamic thresholding strategies.
* **Provide real-world utility** in the form of a probabilistic alert system for volatility-prone trading days.

SHAP analysis is integrated to uncover feature interactions that precede volatility (e.g., “high RSI + declining OBV” may precede reversals), offering not just predictive power but also interpretability.

### **Dataset Summary**

The dataset is sourced via the **Tushare API** and engineered using Python’s `tsta` technical indicator library. It includes:

* **375 daily records** of AtHub stock trading from the past \~18 months
* **32 columns**, including:

  * **Price data**: `open`, `high`, `low`, `close`, `pct_chg`
  * **Volume metrics**: `vol`, `amount`, `volume_obv`, `volume_cmf`, `volume_vpt`, `volume_vwap`, `volume_mfi`
  * **Volatility indicators**: `volatility_bbw`, `volatility_atr`, `volatility_ui`
  * **Trend & momentum indicators**: `trend_macd`, `trend_adx`, `momentum_rsi`, `momentum_wr`, `momentum_roc`, `trend_aroon_up`, etc.

This feature-rich time series provides a robust foundation for testing anomaly detection models under realistic, noisy conditions.


## Questions

- Q1. Can TA features detect anomalies 1–3 days in advance? Which indicators lead?

- Q2. Which features drive predictions? Do they align with financial theory?

- Q3. How do anomaly thresholds (±3% vs. ±5% vs. ±7% price; 1.8x vs. 2.5x volume) impact model performance?

## Analysis plan

Here's a refined **weekly plan** in bullet-point format that incorporates EDA before feature engineering, aligns with your research questions, and includes all required deliverables (write-up, presentation, website). Tools are listed separately for clarity:

### **Weekly Plan: Predicting Abnormal Volatility in AtHub (603881.SH)**

#### **Week 1: Data Collection & Exploratory Analysis (EDA)**
- **Tasks**:
  - Collect 1+ year of OHLCV data for AtHub using Tushare API.
  - Generate TA features (momentum, volume, volatility, trend indicators).
  - Perform EDA:
    - Visualize price/volume trends and anomaly frequency.
    - Check for missing data, outliers, and stationarity.
    - Analyze correlation between raw price/volume metrics.
  - Define preliminary anomaly thresholds (±5% returns, 2× volume).
- **Tools**: `tushare`, `pandas`, `matplotlib`, `ta`, `seaborn`.

#### **Week 2: Feature Engineering & Baseline Model**
- **Tasks**:
  - Refine anomaly labels based on EDA insights.
  - Split data chronologically (e.g., 80% train, 20% test).
  - Train baseline models (XGBoost/LightGBM) and evaluate with accuracy/F1.
- **Research Questions Addressed**:
  - *Q3 (Threshold Impact)*: Test initial thresholds.
- **Tools**: `scikit-learn`, `xgboost`.

#### **Week 3: Model Tuning & Interpretability**
- **Tasks**:
  - Optimize hyperparameters using time-series cross-validation.
  - Compare performance across thresholds (±3%, ±5%, ±7%).
  - Apply SHAP to identify top predictive features and patterns.
  - Test feature lead times (1–3 days pre-anomaly).
- **Research Questions Addressed**:
  - *Q1 (Predictive Horizon)*: Lag feature analysis.
  - *Q2 (Feature Importance)*: SHAP/partial dependence plots.
- **Tools**: `optuna`, `shap`, `statsmodels` (Granger causality).

#### **Week 4: Final Evaluation & Deliverables**
- **Tasks**:
  - **Write-up (1,000–2,000 words)**:
    - Introduction, Methods, Results (SHAP plots, threshold analysis), Conclusion.
  - **Presentation (5 mins)**:
    - Quarto slides covering motivation, methods, key findings, Q&A prep.
  - **Website**:
    - Host report, code, and interactive visualizations (e.g., Plotly dashboards).
  - **Repo Organization**:
    - Logical structure (e.g., `data/`, `notebooks/`, `results/`).
    - Clear `index.qmd` as entry point.
- **Tools**: Quarto, `plotly`, `pkgdown`

