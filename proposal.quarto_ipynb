{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Forecasting Anomalies in AtHub’s Stock Behavior\"\n",
        "subtitle: \"Data-Driven Detection of Local Peaks and Dips\"\n",
        "author: \n",
        "  - name: \"Annabelle Zhu\"\n",
        "    affiliations:\n",
        "      - name: \"College of Information Science, University of Arizona\"\n",
        "description: \"This project explores the predictive modeling of short-term volatility anomalies in the Chinese equity market, with a specific focus on the stock *AtHub (603881.SH)*—a data center infrastructure company. The goal is to develop a machine learning pipeline that can detect abnormal daily price or volume movements using technical analysis (TA) indicators.\"\n",
        "format:\n",
        "  html:\n",
        "    code-tools: true\n",
        "    code-overflow: wrap\n",
        "    code-line-numbers: true\n",
        "    embed-resources: true\n",
        "editor: visual\n",
        "bibliography: references.bib\n",
        "code-annotations: hover\n",
        "execute:\n",
        "  warning: false\n",
        "  echo: false\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "# 📝 Proposal\n",
        "\n",
        "This project proposes the development of an interpretable machine learning model for forecasting short-term volatility anomalies in the Chinese equity market, using AtHub (603881.SH) as a case study. AtHub is a data center infrastructure provider whose stock demonstrates unusually high daily volatility and frequent sensitivity to external events such as government policy announcements [@lin2024datahub]. Rather than predicting stock prices directly—a notoriously noisy and non-stationary target—this study focuses on detecting next-day abnormal price or volume events, defined as daily returns exceeding ±5% or volume spikes greater than 2× the rolling average.\n",
        "\n",
        "We aim to construct a binary classifier that leverages over 30 technical analysis (TA) indicators across momentum, volume, trend, and volatility domains. These features are engineered using the Tushare API and the `tsta` library, covering 218 trading days of AtHub data. The project will incorporate time-aware cross-validation to avoid look-ahead bias and SHAP analysis for post-hoc interpretability. Ensemble models like LightGBM and XGBoost will serve as the backbone of the predictive framework, selected for their robustness in handling noisy, nonlinear tabular data. The final outcome will include an interactive visualization of feature contributions, along with a brief report and presentation.\n",
        "\n",
        "This proposal reflects a practical and scalable approach to market anomaly detection, especially relevant for traders and risk managers seeking data-driven early warning systems.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "# 🎯 High-Level Goal\n",
        "\n",
        "To develop a machine learning classifier that predicts next-day abnormal volatility events in AtHub (603881.SH) stock using technical analysis (TA) indicators, with anomalies defined as price movements exceeding ±5% or volume surges \\>2× the 30-day average."
      ],
      "id": "70c20dc1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: load-pkgs\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "id": "load-pkgs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "# 📊 Dataset"
      ],
      "id": "b3e6f14b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "message": false
      },
      "source": [
        "#| label: load-dataset\n",
        "df = pd.read_csv(\"data/stock_cleaned.csv\")\n",
        "df.head()"
      ],
      "id": "load-dataset",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset info"
      ],
      "id": "7087e3b4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "f\"Dataset contains {df.shape[0]} rows and {df.shape[1]} columns.\""
      ],
      "id": "68926362",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.info()"
      ],
      "id": "1501628e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Summary\n",
        "\n",
        "The dataset is sourced via the **Tushare API** and engineered using Python’s `tsta` technical indicator library. It includes:\n",
        "\n",
        "-   **375 daily records** of AtHub stock trading from the past \\~18 months\n",
        "\n",
        "-   **31 columns**, including:\n",
        "\n",
        "    -   **Price data**: `open`, `high`, `low`, `close`, `pct_chg`\n",
        "    -   **Volume metrics**: `vol`, `amount`, `volume_obv`, `volume_cmf`, `volume_vpt`, `volume_vwap`, `volume_mfi`\n",
        "    -   **Volatility indicators**: `volatility_bbw`, `volatility_atr`, `volatility_ui`\n",
        "    -   **Trend & momentum indicators**: `trend_macd`, `trend_adx`, `momentum_rsi`, `momentum_wr`, `momentum_roc`, `trend_aroon_up`, etc.\n",
        "\n",
        "This feature-rich time series provides a robust foundation for testing anomaly detection models under realistic, noisy conditions.\n",
        "\n",
        "## Target `Anomalies`"
      ],
      "id": "127e97a2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: target-visualization\n",
        "#| fig-cap: Distribution of Anomaly Labels (Target Variable)\n",
        "#| fig-subcap:\n",
        "#|   - Anomaly Class Distribution\n",
        "#|   - Daily Returns Histogram\n",
        "\n",
        "# Calculate anomaly days\n",
        "df['anomaly'] = ((df['pct_chg'].abs() >= 5) | \n",
        "                (df['vol'] > 2 * df['vol'].rolling(30).mean())).astype(int)\n",
        "\n",
        "# Plot\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "df['anomaly'].value_counts().plot(kind='pie', autopct='%1.1f%%', \n",
        "                                 colors=['#66b3ff','#ff9999'], ax=ax1)\n",
        "ax1.set_title('Anomaly Class Distribution')\n",
        "\n",
        "df['pct_chg'].plot(kind='hist', bins=50, color='#66b3ff', ax=ax2)\n",
        "ax2.axvline(x=5, color='red', linestyle='--')\n",
        "ax2.axvline(x=-5, color='red', linestyle='--')\n",
        "ax2.set_title('Daily Returns Distribution (±5% Threshold)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "target-visualization",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Construction Strategy\n",
        "\n",
        "To effectively model price and volume anomalies, we engineered over 30 technical indicators across four core dimensions widely adopted in quantitative trading:\n",
        "\n",
        "-   **Momentum** (e.g., RSI, MACD, Williams %R): capture price velocity and potential reversals.\n",
        "-   **Volume-based** (e.g., OBV, MFI, VPT): track accumulation/distribution behavior.\n",
        "-   **Volatility** (e.g., ATR, Bollinger Band Width, Ulcer Index): quantify market turbulence.\n",
        "-   **Trend strength** (e.g., ADX, Aroon, CCI): detect the emergence or weakening of price trends.\n",
        "\n",
        "These indicators were computed using the `tsta` Python library and merged with daily OHLCV data. We conducted correlation analysis to filter redundant signals and retain complementary ones, as illustrated in the figure below."
      ],
      "id": "2e202c91"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: feature-target-corr\n",
        "#| fig-cap: Correlation Between Features and Target (Anomaly)\n",
        "\n",
        "from scipy.stats import pointbiserialr\n",
        "\n",
        "selected_features = ['momentum_rsi', 'volume_obv', 'volatility_atr', \n",
        "                     'trend_macd_diff', 'volume_vpt', 'trend_adx']\n",
        "\n",
        "corr_with_target = {}\n",
        "for col in selected_features:\n",
        "    corr, _ = pointbiserialr(df['anomaly'], df[col])\n",
        "    corr_with_target[col] = corr\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(x=list(corr_with_target.values()), y=list(corr_with_target.keys()), palette='coolwarm')\n",
        "plt.xlabel('Point Biserial Correlation with Target (Anomaly)')\n",
        "plt.title('Feature-Target Correlation')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "feature-target-corr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This engineered feature space provides interpretable signals that are sensitive to both directional shifts and liquidity changes—two major components in anomaly formation.\n",
        "\n",
        "## Model Development Approach\n",
        "\n",
        "### Data Splitting Strategy\n",
        "\n",
        "Given the time-series nature of stock data, we implement:\n",
        "\n",
        "-   **Chronological split**: First 80% for training, last 20% for testing\n",
        "\n",
        "-   **Walk-forward validation**: Expanding window cross-validation\n",
        "\n",
        "### Evaluation Metrics\n",
        "\n",
        "We prioritize: - **Recall**: Minimizing false negatives (missed anomalies)\n",
        "\n",
        "-   **F1-score**: Balancing precision/recall\n",
        "\n",
        "-   **Matthews Correlation Coefficient**: Robust to class imbalance\n",
        "\n",
        "### Baseline Models\n",
        "\n",
        "| Model | Strengths | Weaknesses |\n",
        "|------------------------|------------------------|------------------------|\n",
        "| **XGBoost** | Handles nonlinear relationships | Requires careful tuning |\n",
        "| **LightGBM** | Efficient with large features | Sensitive to outliers |\n",
        "| **Logistic Regression** | Interpretable coefficients | Limited nonlinear capacity |\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "# 📍 Motivation & Goals\n",
        "\n",
        "**Why AtHub (603881.SH)?** AtHub is a leading Chinese data center infrastructure provider whose stock exhibits unusually high short-term volatility, making it a strong candidate for anomaly-based forecasting. Over the past six months, its daily return volatility ($\\sigma \\approx$ 35%) has far exceeded the industry average ($\\approx$ 22%). Moreover, its price reacts sharply to regulatory announcements and policy shifts, reflecting its sensitivity to macro-level and sector-specific events.\n",
        "\n",
        "This project aims to detect and forecast short-term abnormal volatility events in AtHub’s stock using supervised machine learning. Instead of heuristic rules, we define volatility anomalies using **quantifiable thresholds**: price changes beyond ±5% or trading volumes exceeding 2$\\times$ the 30-day average. Our key goals are:\n",
        "\n",
        "-   **Build an interpretable prediction model** using over 30 engineered technical indicators (e.g., MACD, RSI, OBV, ATR).\n",
        "-   **Evaluate event-driven prediction performance** using time-series-aware cross-validation and dynamic thresholding strategies.\n",
        "-   **Provide real-world utility** in the form of a probabilistic alert system for volatility-prone trading days.\n",
        "\n",
        "SHAP analysis is integrated to uncover feature interactions that precede volatility (e.g., “high RSI + declining OBV” may precede reversals), offering not just predictive power but also interpretability.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "# 👓 Research Questions\n",
        "\n",
        "-   Q1. Can TA features predict anomalies 1–3 days into the future? \n",
        "\n",
        "-   Q2. Which features drive predictions? Do they align with financial theory?\n",
        "\n",
        "-   Q3. How do anomaly thresholds ($\\pm$ 3% vs. $\\pm$ 5% vs. $\\pm$ 7% price; 1.8 $\\times$ vs. 2.5$\\times$ volume) impact model performance?\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "# 🚩 Analysis plan\n",
        "\n",
        "Here's a refined **weekly plan** in bullet-point format that incorporates EDA before feature engineering, aligns with your research questions, and includes all required deliverables (write-up, presentation, website). Tools are listed separately for clarity:\n",
        "\n",
        "## **Weekly Plan: Predicting Abnormal Volatility in AtHub (603881.SH)**\n",
        "\n",
        "#### **Week 1: Data Collection & Exploratory Analysis (EDA)**\n",
        "\n",
        "-   **Tasks**:\n",
        "    -   Collect 1+ year of OHLCV data for AtHub using Tushare API.\n",
        "    -   Generate TA features (momentum, volume, volatility, trend indicators).\n",
        "    -   Perform EDA:\n",
        "        -   Visualize price/volume trends and anomaly frequency.\n",
        "        -   Check for missing data, outliers, and stationarity.\n",
        "        -   Analyze correlation between raw price/volume metrics.\n",
        "    -   Define preliminary anomaly thresholds (\\$\\pm$5% returns, 2$\\times\\$ volume).\n",
        "-   **Tools**: `tushare`, `pandas`, `matplotlib`, `ta`, `seaborn`.\n",
        "\n",
        "#### **Week 2: Feature Engineering & Baseline Model**\n",
        "\n",
        "-   **Tasks**:\n",
        "    -   Refine anomaly labels based on EDA insights.\n",
        "    -   Split data chronologically (e.g., 80% train, 20% test).\n",
        "    -   Train baseline models (XGBoost/LightGBM) and evaluate with accuracy/F1.\n",
        "-   **Research Questions Addressed**:\n",
        "    -   *Q3 (Threshold Impact)*: Test initial thresholds.\n",
        "-   **Tools**: `scikit-learn`, `xgboost`.\n",
        "\n",
        "#### **Week 3: Model Tuning & Interpretability**\n",
        "\n",
        "-   **Tasks**:\n",
        "    -   Optimize hyperparameters using time-series cross-validation.\n",
        "    -   Compare performance across thresholds ($\\pm$ 3%, $\\pm$ 5%, $\\pm$ 7%).\n",
        "    -   Apply SHAP to identify top predictive features and patterns.\n",
        "    -   Test feature lead times (1–3 days pre-anomaly).\n",
        "-   **Research Questions Addressed**:\n",
        "    -   *Q1 (Predictive Horizon)*: Lag feature analysis.\n",
        "    -   *Q2 (Feature Importance)*: SHAP/partial dependence plots.\n",
        "-   **Tools**: `optuna`, `shap`, `statsmodels` (Granger causality).\n",
        "\n",
        "#### **Week 4: Final Evaluation & Deliverables**\n",
        "\n",
        "-   **Tasks**:\n",
        "    -   **Write-up (1,000–2,000 words)**:\n",
        "        -   Introduction, Methods, Results (SHAP plots, threshold analysis), Conclusion.\n",
        "    -   **Presentation (5 mins)**:\n",
        "        -   Quarto slides covering motivation, methods, key findings, Q&A prep.\n",
        "    -   **Website**:\n",
        "        -   Host report, code, and interactive visualizations (e.g., Plotly dashboards).\n",
        "    -   **Repo Organization**:\n",
        "        -   Logical structure (e.g., `data/`, `notebooks/`, `results/`).\n",
        "        -   Clear `index.qmd` as entry point.\n",
        "-   **Tools**: Quarto, `plotly`, `pkgdown`\n",
        "\n",
        "## Expected Outcomes\n",
        "\n",
        "1.  **Threshold Analysis Results**:\n",
        "    -   Precision-recall curves for $\\pm$ 3% vs. $\\pm$ 5% vs. $\\pm$ 7% thresholds\n",
        "    -   Optimal threshold selection based on trading costs\n",
        "2.  **Top Predictive Features**:\n",
        "    -   SHAP summary plot of top influential indicators\n",
        "    -   Temporal importance patterns (e.g., volume leads price)\n",
        "3.  **Practical Trading Rules**:\n",
        "    -   Actionable signals like:\\\n",
        "        *\"When RSI \\> 70 AND OBV \\< 30-day average* $\\to$ 67% probability of next-day drop \\>5%\"\n",
        "4.  **Interactive Dashboard**:\n",
        "    -   Dynamic visualization of anomaly predictions\n",
        "    -   Threshold adjustment interface\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "# 📁 Repository Organization\n",
        "\n",
        "| Folder / File Name | Description |\n",
        "|--------------------|------------------------------------|\n",
        "| `.quarto/`         | Internal Quarto system files; manages cache and config for rendering. Not manually edited. |\n",
        "| `_extra/`          | Holds supplementary files or artifacts not directly part of deliverables. |\n",
        "| `_freeze/`         | Stores frozen snapshots of document outputs to ensure reproducibility across builds. |\n",
        "| `audio/`           | Contains voice recordings for presentation. Each file corresponds to a slide in the presentation. |\n",
        "| `_site/`           | Output folder generated when the site is rendered; contains final HTML files. |\n",
        "| `data/`            | Contains all datasets used in the project, both raw and processed. Includes README for data schema and source. |\n",
        "| `images/`          | Stores all image assets, including plots and figures used in `.qmd` files. |\n",
        "| `style/`           | Contains custom theming files (e.g., `customtheming.scss`) used to style the website. |\n",
        "| `index.qmd`        | Landing page of the Quarto website; typically includes a high-level **project overview** or introduction. |\n",
        "| `about.qmd`        | Additional project background or author info. Can serve as a **detailed project description**. |\n",
        "| `proposal.qmd`     | Contains the research proposal, including motivation, methodology, timeline, and repo organization. |\n",
        "| `presentation.qmd` | A Quarto-based presentation (slides) summarizing key findings from the final report. |"
      ],
      "id": "044cae78"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\admin.DESKTOP-GJO8JEU.001\\AppData\\Local\\Programs\\Python\\Python312\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}